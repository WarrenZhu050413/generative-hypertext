<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Codex MCP Usage Guide - Offloading Heavy Work to Subagents</title>
    <style>
        :root {
            --ink-black: #2b2b2b;
            --chinese-red: #8B0000;
            --chinese-gold: #FFD700;
            --paper-beige: #F5F0E8;
            --light-cream: #FFFEF7;
            --level-1: #8B0000;
            --level-2: #CD5C5C;
            --level-3: #666;
            --level-4: #999;
        }

        body {
            background: linear-gradient(135deg, var(--paper-beige) 0%, var(--light-cream) 100%);
            color: var(--ink-black);
            margin: 0;
            padding: 8px;
            width: 100vw;
            max-width: 100%;
            line-height: 1.3;
            font-size: 14px;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        .container {
            width: 100%;
            padding: 0;
            margin: 0;
        }

        h1 {
            font-size: 26px;
            font-weight: 900;
            margin: 6px 0;
            padding: 8px 6px;
            background: linear-gradient(135deg, var(--chinese-red), #CD5C5C);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            letter-spacing: -0.5px;
        }

        h2 {
            font-size: 18px;
            font-weight: 700;
            margin: 10px 0 6px 0;
            padding: 6px;
            border-left: 4px solid var(--chinese-red);
            background: rgba(139, 0, 0, 0.04);
            color: var(--level-1);
        }

        h3 {
            font-size: 15px;
            font-weight: 600;
            margin: 6px 0 4px 8px;
            color: var(--level-2);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            font-size: 13px;
        }

        h4 {
            font-size: 13px;
            font-weight: 600;
            margin: 4px 0 2px 16px;
            color: var(--level-3);
        }

        .collapsible {
            margin: 6px 0;
            width: 100%;
        }

        .collapsible-header {
            cursor: pointer;
            padding: 6px 10px;
            background: linear-gradient(135deg, rgba(139, 0, 0, 0.06), rgba(255, 215, 0, 0.03));
            border-left: 3px solid var(--chinese-gold);
            display: flex;
            align-items: center;
            justify-content: space-between;
            user-select: none;
            transition: all 0.2s ease;
            font-weight: 600;
            font-size: 14px;
        }

        .collapsible-header:hover {
            background: linear-gradient(135deg, rgba(139, 0, 0, 0.12), rgba(255, 215, 0, 0.06));
        }

        .collapsible-header .arrow {
            display: inline-block;
            transition: transform 0.3s ease;
            color: var(--chinese-red);
            font-size: 11px;
            margin-right: 6px;
        }

        .collapsible.open .arrow {
            transform: rotate(90deg);
        }

        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
            padding: 0 10px;
            margin-left: 16px;
        }

        .collapsible.open .collapsible-content {
            max-height: 8000px;
            padding: 10px;
        }

        .critical-box {
            background: linear-gradient(135deg, rgba(255, 215, 0, 0.15), white);
            border: 2px solid var(--chinese-gold);
            padding: 10px;
            margin: 10px 0;
            border-radius: 3px;
        }

        .critical-box h2 {
            color: var(--chinese-red);
            margin-top: 0;
            background: none;
            border: none;
            padding: 0;
        }

        .warning-box {
            background: rgba(255, 69, 0, 0.08);
            border-left: 4px solid #FF4500;
            padding: 8px;
            margin: 8px 0;
        }

        .info-box {
            background: rgba(70, 130, 180, 0.08);
            border-left: 4px solid #4682B4;
            padding: 8px;
            margin: 8px 0;
        }

        .two-column-layout {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
            margin: 8px 0;
        }

        .card {
            background: white;
            border: 1px solid rgba(139, 0, 0, 0.2);
            border-radius: 3px;
            padding: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.08);
        }

        .card.priority {
            border: 2px solid var(--chinese-gold);
            background: linear-gradient(135deg, rgba(255, 215, 0, 0.08), white);
        }

        code {
            background: rgba(139, 0, 0, 0.06);
            padding: 2px 5px;
            border-radius: 2px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 12px;
            color: var(--chinese-red);
        }

        pre {
            background: #2b2b2b;
            color: #f8f8f2;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
            margin: 8px 0;
            font-size: 12px;
            line-height: 1.4;
        }

        pre code {
            background: none;
            color: inherit;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 8px 0;
            font-size: 13px;
        }

        th {
            background: linear-gradient(135deg, var(--chinese-red), #CD5C5C);
            color: white;
            padding: 6px;
            text-align: left;
            font-weight: 600;
            font-size: 12px;
        }

        td {
            border: 1px solid rgba(139, 0, 0, 0.15);
            padding: 6px;
            vertical-align: top;
        }

        tr:nth-child(even) {
            background: rgba(139, 0, 0, 0.03);
        }

        .dense-list {
            list-style: none;
            padding: 0;
            margin-left: 12px;
        }

        .dense-list li {
            padding: 3px 0 3px 16px;
            border-left: 2px solid transparent;
            position: relative;
            line-height: 1.4;
        }

        .dense-list li:before {
            content: "▸";
            position: absolute;
            left: 0;
            color: var(--chinese-red);
            font-size: 11px;
        }

        .dense-list li strong {
            color: var(--level-2);
            font-weight: 600;
        }

        .indent-1 { margin-left: 16px; }
        .indent-2 { margin-left: 32px; }
        .indent-3 { margin-left: 48px; }

        .divider {
            height: 1px;
            background: linear-gradient(90deg, var(--chinese-red), transparent);
            margin: 12px 0;
        }

        button, .toggle-all {
            background: linear-gradient(135deg, var(--chinese-red), #CD5C5C);
            color: white;
            border: 1px solid rgba(255, 215, 0, 0.4);
            padding: 4px 10px;
            margin: 4px 4px 8px 0;
            font-size: 12px;
            cursor: pointer;
            border-radius: 3px;
            transition: all 0.2s ease;
        }

        button:hover {
            transform: translateY(-1px);
            box-shadow: 0 3px 10px rgba(139, 0, 0, 0.3);
            border-color: var(--chinese-gold);
        }

        .tag {
            display: inline-block;
            padding: 2px 6px;
            margin: 2px;
            font-size: 11px;
            border-radius: 2px;
            font-weight: 600;
        }

        .tag.danger { background: rgba(139, 0, 0, 0.15); color: var(--chinese-red); }
        .tag.warning { background: rgba(255, 165, 0, 0.15); color: #FF8C00; }
        .tag.safe { background: rgba(34, 139, 34, 0.15); color: #228B22; }
        .tag.info { background: rgba(70, 130, 180, 0.15); color: #4682B4; }
    </style>
</head>
<body>
    <div class="container">
        <h1>🤖 Codex MCP Usage Guide: Offloading Heavy Work to Subagents</h1>

        <div class="critical-box">
            <h2>🎯 Quick Start - What You Need to Know</h2>
            <ul class="dense-list">
                <li><strong>Purpose:</strong> Use Codex MCP as a subagent to offload heavy analytical work, plan reviews, architectural analysis, bug chasing, and token-intensive tasks</li>
                <li><strong>Two Tools:</strong> <code>mcp__codex__codex</code> (start new session) and <code>mcp__codex__codex-reply</code> (continue session)</li>
                <li><strong>Model:</strong> Always use <code>"model": "gpt-5-codex"</code> for best reasoning capabilities</li>
                <li><strong>Sandbox:</strong> Always use <code>"sandbox_mode": "read-only"</code> - Codex is for analysis, not writing</li>
                <li><strong>Configuration:</strong> Pass config as inline object (NOT file path) to avoid hanging</li>
                <li><strong>ConversationId:</strong> The MCP tool RETURNS the conversationId in its response - extract it to continue the conversation</li>
                <li><strong>Reasoning Settings:</strong> Always use <code>"model_reasoning_effort": "high"</code> and <code>"model_reasoning_summary": "concise"</code></li>
            </ul>
        </div>

        <button class="toggle-all" onclick="toggleAll()">Expand All Sections</button>

        <div class="divider"></div>

        <!-- Core Concepts -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Core Concepts: Why Use Codex MCP?</span>
            </div>
            <div class="collapsible-content">
                <ul class="dense-list">
                    <li><strong>Token Conservation:</strong> Offload large analytical tasks to Codex to avoid cluttering your main context window</li>
                    <li><strong>Persistent Sessions:</strong> Sessions are saved to <code>~/.codex/sessions/YYYY/MM/DD/*.jsonl</code> - you can resume them later</li>
                    <li><strong>Web Search:</strong> Enable web research capabilities to fetch latest documentation, articles, and resources</li>
                    <li><strong>Sandboxed Execution:</strong> Control file access and command execution with fine-grained sandbox policies</li>
                    <li><strong>Specialized Work:</strong> Plan reviews, architecture simplifications, bug investigations, code refactoring analysis</li>
                </ul>

                <div class="two-column-layout">
                    <div class="card priority">
                        <h4>✅ Good Use Cases</h4>
                        <ul class="dense-list">
                            <li>Reviewing large plans or architecture docs</li>
                            <li>Researching best practices online</li>
                            <li>Deep code analysis across multiple files</li>
                            <li>Bug hunting in complex codebases</li>
                            <li>Generating comprehensive reports</li>
                            <li>Proposing refactoring strategies</li>
                        </ul>
                    </div>
                    <div class="card">
                        <h4>❌ Not Ideal For</h4>
                        <ul class="dense-list">
                            <li>Quick single-file edits</li>
                            <li>Simple questions with known answers</li>
                            <li>Real-time collaborative editing</li>
                            <li>Tasks requiring immediate user feedback</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Tool 1: Starting Sessions -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Tool 1: mcp__codex__codex - Starting New Sessions</span>
            </div>
            <div class="collapsible-content">
                <h3>Basic Usage (Standard Template)</h3>
                <pre><code># Start a session - returns conversationId for continuation
result = mcp__codex__codex(
    prompt="Analyze the codebase architecture and suggest simplifications",
    config={
        "tools": {"web_search": true},
        "model": "gpt-5-codex",              # Always use gpt-5-codex
        "approval_policy": "never",
        "sandbox_mode": "read-only",         # Always read-only for analysis
        "model_reasoning_effort": "high",    # Always high
        "model_reasoning_summary": "concise"  # Concise bullet-style reasoning
    }
)

# Extract conversationId from the response
conversation_id = result["conversationId"]</code></pre>

                <h3>All Parameters</h3>
                <table>
                    <tr>
                        <th>Parameter</th>
                        <th>Type</th>
                        <th>Description</th>
                        <th>Required</th>
                    </tr>
                    <tr>
                        <td><code>prompt</code></td>
                        <td>string</td>
                        <td>Initial user prompt to start the conversation</td>
                        <td>✅ Yes</td>
                    </tr>
                    <tr>
                        <td><code>config</code></td>
                        <td>object</td>
                        <td>Configuration overrides (see config options below)</td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>model</code></td>
                        <td>string</td>
                        <td>Model name: <code>"o3"</code>, <code>"o4-mini"</code>, <code>"gpt-5"</code>, <code>"gpt-5-codex"</code></td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>approval-policy</code></td>
                        <td>string</td>
                        <td><code>"untrusted"</code>, <code>"on-failure"</code>, <code>"on-request"</code>, <code>"never"</code></td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>sandbox</code></td>
                        <td>string</td>
                        <td><code>"read-only"</code>, <code>"workspace-write"</code>, <code>"danger-full-access"</code></td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>cwd</code></td>
                        <td>string</td>
                        <td>Working directory (absolute or relative path)</td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>profile</code></td>
                        <td>string</td>
                        <td>Named profile from <code>config.toml</code></td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>base-instructions</code></td>
                        <td>string</td>
                        <td>Override default instructions</td>
                        <td>❌ No</td>
                    </tr>
                    <tr>
                        <td><code>include-plan-tool</code></td>
                        <td>boolean</td>
                        <td>Include planning tool in conversation</td>
                        <td>❌ No</td>
                    </tr>
                </table>

                <div class="critical-box">
                    <h3 style="margin: 0 0 6px 0; text-transform: none;">✅ ConversationId is RETURNED by the MCP Tool</h3>
                    <p style="margin-bottom: 6px;">The <code>mcp__codex__codex</code> tool returns a response object containing the <code>conversationId</code>. You extract it directly from the return value:</p>
                    <pre><code>result = mcp__codex__codex(...)
conversation_id = result["conversationId"]  # Extract this!

# Use it for continuation:
mcp__codex__codex-reply(
    conversationId=conversation_id,
    prompt="Follow-up question"
)</code></pre>
                </div>

                <h3>Complete Response Format</h3>
                <pre><code>{
    "conversationId": "7f9f9a2e-1b3c-4c7a-9b0e-123456789abc",  # ← Extract this!
    "model": "gpt-5-codex",
    "reasoningEffort": "high",
    "rolloutPath": "/Users/wz/.codex/sessions/2025/10/07/rollout-2025-10-07T14-25-30-..."
}</code></pre>
            </div>
        </div>

        <!-- Tool 2: Resuming Sessions -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Tool 2: mcp__codex__codex-reply - Resuming Sessions</span>
            </div>
            <div class="collapsible-content">
                <h3>Basic Usage</h3>
                <pre><code>mcp__codex__codex-reply(
    conversationId="7f9f9a2e-1b3c-4c7a-9b0e-123456789abc",
    prompt="Now generate a detailed implementation plan based on your analysis"
)</code></pre>

                <h3>Parameters</h3>
                <table>
                    <tr>
                        <th>Parameter</th>
                        <th>Type</th>
                        <th>Description</th>
                        <th>Required</th>
                    </tr>
                    <tr>
                        <td><code>conversationId</code></td>
                        <td>string</td>
                        <td>The conversation ID from the initial <code>codex</code> call or from session files</td>
                        <td>✅ Yes</td>
                    </tr>
                    <tr>
                        <td><code>prompt</code></td>
                        <td>string</td>
                        <td>Next user message to continue the conversation</td>
                        <td>✅ Yes</td>
                    </tr>
                </table>

                <div class="info-box">
                    <strong>📝 Note:</strong> The conversation maintains full context from previous messages, including all files read, commands run, and analysis performed.
                </div>
            </div>
        </div>

        <!-- Configuration Options -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Configuration Options Deep Dive</span>
            </div>
            <div class="collapsible-content">
                <h3>Sandbox Modes</h3>
                <table>
                    <tr>
                        <th>Mode</th>
                        <th>File Read</th>
                        <th>File Write</th>
                        <th>Network</th>
                        <th>Use Case</th>
                    </tr>
                    <tr>
                        <td><code>read-only</code> <span class="tag safe">SAFE</span></td>
                        <td>✅ Any file</td>
                        <td>❌ Blocked</td>
                        <td>❌ Blocked</td>
                        <td>Analysis, reviews, research - no modifications</td>
                    </tr>
                    <tr>
                        <td><code>workspace-write</code> <span class="tag warning">MODERATE</span></td>
                        <td>✅ Any file</td>
                        <td>✅ CWD + /tmp</td>
                        <td>❌ Blocked*</td>
                        <td>Code generation, refactoring within workspace</td>
                    </tr>
                    <tr>
                        <td><code>danger-full-access</code> <span class="tag danger">RISKY</span></td>
                        <td>✅ Any file</td>
                        <td>✅ Anywhere</td>
                        <td>✅ Allowed</td>
                        <td>⚠️ Only in Docker or when you fully trust the task</td>
                    </tr>
                </table>

                <p class="indent-1" style="font-size: 12px; color: var(--level-4);">* Network can be enabled in workspace-write mode via config: <code>sandbox_workspace_write.network_access = true</code></p>

                <h3>Approval Policies</h3>
                <table>
                    <tr>
                        <th>Policy</th>
                        <th>Behavior</th>
                        <th>Best For</th>
                    </tr>
                    <tr>
                        <td><code>untrusted</code></td>
                        <td>Prompt before running any "untrusted" command</td>
                        <td>Interactive sessions where you want control</td>
                    </tr>
                    <tr>
                        <td><code>on-failure</code></td>
                        <td>Ask permission only when sandboxed command fails</td>
                        <td>Auto mode - retry failed commands with approval</td>
                    </tr>
                    <tr>
                        <td><code>on-request</code></td>
                        <td>Model decides when to escalate and ask permission</td>
                        <td>Smart auto mode - trust model judgment</td>
                    </tr>
                    <tr>
                        <td><code>never</code> <span class="tag info">RECOMMENDED FOR MCP</span></td>
                        <td>Never ask - work within sandbox constraints</td>
                        <td>Non-interactive subagent tasks, CI/CD pipelines</td>
                    </tr>
                </table>

                <div class="warning-box">
                    <strong>💡 For MCP Subagent Use:</strong> Almost always use <code>"never"</code> approval policy. You can't respond to approval prompts when Codex is running as a subagent, so it will hang waiting for input.
                </div>

                <h3>Essential Config Object Options</h3>
                <pre><code>config={
    # Enable web search tool (critical for research tasks)
    "tools": {"web_search": true},

    # Model settings (ALWAYS use gpt-5-codex)
    "model": "gpt-5-codex",                # Always gpt-5-codex!
    "model_provider": "openai",

    # Reasoning configuration (ALWAYS use these settings)
    "model_reasoning_effort": "high",       # Always "high"!
    "model_reasoning_summary": "concise",  # Concise bullet-style reasoning

    # Sandbox and approvals (ALWAYS read-only for analysis)
    "approval_policy": "never",             # Required for non-interactive use
    "sandbox_mode": "read-only",            # Always read-only!

    # Environment (optional)
    "shell_environment_policy": {
        "inherit": "core",  # all, core, none
        "exclude": ["AWS_*", "AZURE_*"]
    }
}</code></pre>

                <div class="warning-box">
                    <strong>⚠️ Note on model_verbosity:</strong> The <code>model_verbosity</code> setting only works with GPT-5 family models, NOT <code>gpt-5-codex</code>. For gpt-5-codex, use <code>model_reasoning_summary</code> to control output detail. See below for model_verbosity details.
                </div>

                <h3>What About model_verbosity? (GPT-5 Only)</h3>
                <div class="info-box">
                    <p style="margin-bottom: 6px;"><strong>Important:</strong> <code>model_verbosity</code> does NOT work with <code>gpt-5-codex</code>. It only affects GPT-5 family models.</p>
                </div>

                <h4>For GPT-5 Models (NOT gpt-5-codex)</h4>
                <table>
                    <tr>
                        <th>Value</th>
                        <th>Behavior</th>
                        <th>Use Case</th>
                    </tr>
                    <tr>
                        <td><code>"low"</code></td>
                        <td>Terse, minimal responses - cuts down on explanation length</td>
                        <td>Status updates, quick answers, token-constrained scenarios</td>
                    </tr>
                    <tr>
                        <td><code>"medium"</code></td>
                        <td>Balanced responses - normal conversational length (default)</td>
                        <td>Standard day-to-day coding assistance</td>
                    </tr>
                    <tr>
                        <td><code>"high"</code></td>
                        <td>Expanded explanations - longer, more thorough responses</td>
                        <td>Walkthroughs, onboarding docs, educational content, deep reviews</td>
                    </tr>
                </table>

                <h4>How It Works (GPT-5 Only)</h4>
                <ul class="dense-list">
                    <li><strong>API Field:</strong> Codex adds <code>text: { "verbosity": "low" }</code> to the Responses API payload</li>
                    <li><strong>Token Impact:</strong> "high" encourages longer responses → more output tokens; "low" curbs response length</li>
                    <li><strong>Model Decision:</strong> The model interprets the verbosity hint and adjusts output length accordingly</li>
                    <li><strong>Independent Setting:</strong> Works alongside <code>model_reasoning_summary</code> - they control different aspects</li>
                </ul>

                <div class="warning-box">
                    <strong>⚠️ Not for gpt-5-codex:</strong> Since you're using <code>gpt-5-codex</code>, this setting is ignored. Control output through prompting and <code>model_reasoning_summary</code> instead.
                </div>
            </div>
        </div>

        <!-- Reasoning Summary Settings -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Understanding model_reasoning_summary (Critical Setting)</span>
            </div>
            <div class="collapsible-content">
                <h3>What is model_reasoning_summary?</h3>
                <p>Controls whether and how the model's internal reasoning process is shown in the output. This is crucial for understanding HOW Codex arrived at its conclusions.</p>

                <h3>Options & Behavior</h3>
                <table>
                    <tr>
                        <th>Value</th>
                        <th>Output Behavior</th>
                        <th>Tokens Used</th>
                        <th>Use Case</th>
                    </tr>
                    <tr>
                        <td><code>"auto"</code></td>
                        <td>API decides detail level automatically</td>
                        <td>Moderate</td>
                        <td>Default balanced behavior - let the model decide</td>
                    </tr>
                    <tr>
                        <td><code>"concise"</code> <span class="tag info">RECOMMENDED</span></td>
                        <td>Short bullet-style reasoning recap</td>
                        <td>Lower (optimal balance)</td>
                        <td>Clear reasoning without verbosity - best for most tasks</td>
                    </tr>
                    <tr>
                        <td><code>"detailed"</code></td>
                        <td>Full reasoning explanation showing thought process</td>
                        <td>Higher (20-50% more tokens)</td>
                        <td>Deep auditing when you need maximum transparency</td>
                    </tr>
                    <tr>
                        <td><code>"none"</code></td>
                        <td>No reasoning summary shown at all</td>
                        <td>Lowest (reasoning tokens not included)</td>
                        <td>Minimize exposed reasoning or reduce token costs</td>
                    </tr>
                </table>

                <div class="critical-box">
                    <h3 style="margin: 0 0 6px 0; text-transform: none;">💡 Recommendation: Always Use "concise"</h3>
                    <p style="margin-bottom: 6px;">For Codex MCP analytical work, <code>"concise"</code> provides the optimal balance:</p>
                    <ul class="dense-list">
                        <li><strong>Transparency:</strong> See the key reasoning steps without verbosity</li>
                        <li><strong>Token Efficiency:</strong> Get reasoning insights without token overhead</li>
                        <li><strong>Clarity:</strong> Bullet-style summaries are easier to scan</li>
                        <li><strong>Quality Validation:</strong> Verify the analysis logic is sound</li>
                    </ul>
                    <pre style="margin-top: 8px;"><code>"model_reasoning_summary": "concise"  # Always use this!</code></pre>
                    <p style="font-size: 11px; margin-top: 6px; color: var(--level-3);">Use <code>"detailed"</code> only when you need maximum transparency for deep auditing or debugging complex reasoning chains.</p>
                </div>

                <h3>Model Support</h3>
                <p>Supported by: <code>o3</code>, <code>o4-mini</code>, <code>gpt-5</code>, <strong><code>gpt-5-codex</code> ✅</strong>, and any <code>codex-*</code> models.</p>

                <h3>Token Implications</h3>
                <ul class="dense-list">
                    <li><strong>"concise":</strong> Optimal balance - get reasoning insights with minimal token overhead</li>
                    <li><strong>"detailed":</strong> Adds <code>reasoning_token_count</code> - expect 20-50% more tokens than "concise"</li>
                    <li><strong>"none":</strong> Suppresses reasoning entirely - saves tokens but loses transparency</li>
                    <li><strong>For analysis tasks:</strong> "concise" provides transparency without bloat</li>
                </ul>

                <div class="info-box">
                    <strong>📊 What You See:</strong> With <code>"concise"</code>, the TUI shows an italicized block with bullet-style reasoning steps. With <code>"detailed"</code>, you get fuller explanations. With <code>"none"</code>, the block is completely removed.
                </div>
            </div>
        </div>

        <!-- Web Search -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Enabling Web Search (Critical Feature)</span>
            </div>
            <div class="collapsible-content">
                <h3>Why Web Search Matters</h3>
                <ul class="dense-list">
                    <li><strong>Latest Documentation:</strong> Fetch current API docs, library updates, framework changes</li>
                    <li><strong>Research Best Practices:</strong> Find solutions to specific problems from Stack Overflow, GitHub, blogs</li>
                    <li><strong>Competitive Analysis:</strong> Study how other projects solve similar problems</li>
                    <li><strong>Verification:</strong> Cross-check assumptions against authoritative sources</li>
                </ul>

                <h3>How to Enable</h3>
                <div class="two-column-layout">
                    <div class="card priority">
                        <h4>Via MCP Config Object</h4>
                        <pre><code>config={
    "tools": {
        "web_search": true
    }
}</code></pre>
                    </div>
                    <div class="card">
                        <h4>Via CLI Flag (Reference)</h4>
                        <pre><code>codex --search "research X"</code></pre>
                        <p style="font-size: 11px; margin-top: 4px;">CLI equivalent: <code>--search</code> flag enables the native Responses API <code>web_search</code> tool</p>
                    </div>
                </div>

                <div class="info-box">
                    <strong>🔍 Alias:</strong> You can also use <code>web_search_request</code> instead of <code>web_search</code> in the tools config - they're the same.
                </div>

                <h3>Example: Research Task with Web Search</h3>
                <pre><code>result = mcp__codex__codex(
    prompt="""Research the latest best practices for React Server Components in Next.js 15.
    Find official documentation, blog posts, and real-world examples.
    Summarize the key patterns and anti-patterns.""",
    config={
        "tools": {"web_search": true},     # Enable web research
        "model": "gpt-5-codex",             # Always gpt-5-codex
        "model_reasoning_effort": "high",   # Always high
        "model_reasoning_summary": "concise",  # Concise reasoning bullets
        "approval_policy": "never",
        "sandbox_mode": "read-only"         # Always read-only
    }
)

# ConversationId is in the response:
conv_id = result["conversationId"]</code></pre>
            </div>
        </div>

        <!-- Session Management -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Session Management: Finding and Resuming Sessions</span>
            </div>
            <div class="collapsible-content">
                <h3>Session Storage Location</h3>
                <p>All Codex sessions are stored in: <code>~/.codex/sessions/YYYY/MM/DD/*.jsonl</code></p>

                <h3>Session File Naming Pattern</h3>
                <pre><code>rollout-2025-10-07T14-25-30-&lt;conversation-id&gt;.jsonl</code></pre>

                <h3>Finding Session IDs</h3>
                <div class="two-column-layout">
                    <div class="card priority">
                        <h4>Method 1: From MCP Response</h4>
                        <p>Save the <code>conversationId</code> from the initial <code>codex</code> call:</p>
                        <pre><code>{
    "conversationId": "0199ac70-...",
    ...
}</code></pre>
                    </div>
                    <div class="card">
                        <h4>Method 2: Browse Session Files</h4>
                        <pre><code># List recent sessions
ls -lt ~/.codex/sessions/2025/10/07/

# Extract conversation ID
# Format: rollout-...-&lt;ID&gt;.jsonl</code></pre>
                    </div>
                </div>

                <h3>CLI Resume Commands (For Reference)</h3>
                <table>
                    <tr>
                        <th>Command</th>
                        <th>Description</th>
                    </tr>
                    <tr>
                        <td><code>codex resume</code></td>
                        <td>Opens interactive picker of recent sessions</td>
                    </tr>
                    <tr>
                        <td><code>codex resume --last</code></td>
                        <td>Resumes most recent session</td>
                    </tr>
                    <tr>
                        <td><code>codex resume &lt;SESSION_ID&gt;</code></td>
                        <td>Resumes specific session by ID</td>
                    </tr>
                    <tr>
                        <td><code>codex exec resume --last "prompt"</code></td>
                        <td>Non-interactive resume with new prompt</td>
                    </tr>
                </table>

                <div class="info-box">
                    <strong>📝 MCP Usage:</strong> For MCP, you don't use CLI commands. Instead, you:
                    <ol style="margin-left: 20px; margin-top: 4px;">
                        <li>Extract the <code>conversationId</code> from the first <code>codex</code> response</li>
                        <li>Pass it to <code>codex-reply</code> with your next prompt</li>
                        <li>Repeat step 2 for each follow-up message</li>
                    </ol>
                </div>
            </div>
        </div>

        <!-- Common Patterns -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Common Usage Patterns & Examples</span>
            </div>
            <div class="collapsible-content">

                <div class="card priority" style="margin-bottom: 12px;">
                    <h3>Pattern 1: Plan Review & Analysis (Read-Only)</h3>
                    <pre><code># Step 1: Start analysis session (returns conversationId)
result = mcp__codex__codex(
    prompt="""Review the plan in docs/architecture/redesign_plan.md.
    Check for:
    - Missing edge cases
    - Implementation complexity
    - Potential bottlenecks
    - Better alternatives""",
    config={
        "tools": {"web_search": true},
        "approval_policy": "never",
        "sandbox_mode": "read-only",
        "model_reasoning_effort": "high",  # Always high!
        "model_reasoning_summary": "concise"
    }
)

# Extract conversationId from the MCP response
conversation_id = result["conversationId"]

# Step 2: Continue the conversation using the ID
mcp__codex__codex-reply(
    conversationId=conversation_id,
    prompt="Based on your analysis, propose a simplified approach"
)</code></pre>
                </div>

                <div class="card priority" style="margin-bottom: 12px;">
                    <h3>Pattern 2: Research & Documentation (Read-Only + Web Search)</h3>
                    <pre><code>result = mcp__codex__codex(
    prompt="""Research the latest approaches to real-time collaboration in web apps.
    Focus on:
    - CRDT implementations (Yjs, Automerge)
    - Operational Transform alternatives
    - Conflict resolution strategies

    Provide code examples and performance comparisons.""",
    config={
        "tools": {"web_search": true},   # Critical for research!
        "model": "gpt-5-codex",           # Always gpt-5-codex
        "approval_policy": "never",
        "sandbox_mode": "read-only",      # Always read-only
        "model_reasoning_effort": "high", # Always high
        "model_reasoning_summary": "concise"
    }
)

conv_id = result["conversationId"]  # Returned by the tool!</code></pre>
                </div>

                <div class="card priority" style="margin-bottom: 12px;">
                    <h3>Pattern 3: Bug Investigation (Read-Only)</h3>
                    <pre><code>result = mcp__codex__codex(
    prompt="""Investigate the memory leak in src/services/websocket.ts.
    Analyze:
    - Event listener cleanup patterns
    - Connection lifecycle management
    - Potential circular references

    Cross-reference with similar issues in the codebase.""",
    config={
        "tools": {"web_search": true},
        "approval_policy": "never",
        "sandbox_mode": "read-only",
        "model_reasoning_effort": "high",  # Always high!
        "cwd": "/Users/wz/Desktop/myproject"
    }
)

conv_id = result["conversationId"]</code></pre>
                </div>

                <div class="card" style="margin-bottom: 12px;">
                    <h3>Pattern 4: Analysis with Context (Read-Only)</h3>
                    <pre><code>result = mcp__codex__codex(
    prompt="""Analyze the test coverage in tests/components/ and suggest:
    - Missing test cases for critical paths
    - Edge cases not covered
    - Opportunities for better test organization""",
    config={
        "model": "gpt-5-codex",           # Always gpt-5-codex
        "approval_policy": "never",
        "sandbox_mode": "read-only",      # Always read-only for analysis
        "model_reasoning_effort": "high",
        "model_reasoning_summary": "concise",
        "cwd": "/Users/wz/Desktop/myproject"
    }
)

conv_id = result["conversationId"]</code></pre>
                    <p style="font-size: 11px; margin-top: 4px; color: var(--level-3);">Note: Codex MCP is for analysis, not code generation. Use read-only mode.</p>
                </div>

                <div class="card" style="margin-bottom: 12px;">
                    <h3>Pattern 5: Multi-Turn Conversation (Session Continuation)</h3>
                    <pre><code># Turn 1: Initial analysis (returns conversationId)
result1 = mcp__codex__codex(
    prompt="Analyze the component architecture in src/components/",
    config={
        "model": "gpt-5-codex",              # Always gpt-5-codex
        "sandbox_mode": "read-only",         # Always read-only
        "approval_policy": "never",
        "model_reasoning_effort": "high",    # Always high
        "model_reasoning_summary": "concise"
    }
)

# Extract the conversationId from the response
conv_id = result1["conversationId"]

# Turn 2: Continue the same conversation
result2 = mcp__codex__codex-reply(
    conversationId=conv_id,
    prompt="Focus on the props drilling issues you identified. Show examples."
)

# Turn 3: Further continuation
result3 = mcp__codex__codex-reply(
    conversationId=conv_id,
    prompt="Propose architectural patterns to fix these issues."
)</code></pre>
                </div>
            </div>
        </div>

        <!-- Your CLI vs MCP -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>CLI Command Translation: Your Flags → MCP Config</span>
            </div>
            <div class="collapsible-content">
                <h3>Your Current CLI Command</h3>
                <pre><code>codex --dangerously-bypass-approvals-and-sandbox --search</code></pre>

                <h3>MCP Equivalent</h3>
                <pre><code>mcp__codex__codex(
    prompt="Your task here",
    config={
        "tools": {"web_search": true},           # --search
        "approval_policy": "never",              # Part of --dangerously-bypass...
        "sandbox_mode": "danger-full-access",    # Part of --dangerously-bypass...
        "model_reasoning_effort": "high"         # Always high for MCP!
    }
)</code></pre>

                <div class="warning-box">
                    <strong>⚠️ Safer Alternative for MCP:</strong> The <code>--dangerously-bypass-approvals-and-sandbox</code> flag is very permissive. For most MCP tasks, use:
                    <pre><code>config={
    "tools": {"web_search": true},
    "approval_policy": "never",
    "sandbox_mode": "read-only",         # Safer for analysis tasks
    "model_reasoning_effort": "high"     # Always high!
}</code></pre>
                </div>

                <h3>Common CLI Flags → MCP Config Mapping</h3>
                <table>
                    <tr>
                        <th>CLI Flag</th>
                        <th>MCP Config</th>
                    </tr>
                    <tr>
                        <td><code>--search</code></td>
                        <td><code>"tools": {"web_search": true}</code></td>
                    </tr>
                    <tr>
                        <td><code>--model o3</code></td>
                        <td><code>"model": "o3"</code></td>
                    </tr>
                    <tr>
                        <td><code>--sandbox read-only</code></td>
                        <td><code>"sandbox_mode": "read-only"</code></td>
                    </tr>
                    <tr>
                        <td><code>--ask-for-approval never</code></td>
                        <td><code>"approval_policy": "never"</code></td>
                    </tr>
                    <tr>
                        <td><code>--full-auto</code></td>
                        <td><code>"approval_policy": "on-failure", "sandbox_mode": "workspace-write"</code></td>
                    </tr>
                    <tr>
                        <td><code>--cd /path</code></td>
                        <td><code>"cwd": "/path"</code></td>
                    </tr>
                    <tr>
                        <td><code>--profile search</code></td>
                        <td><code>"profile": "search"</code></td>
                    </tr>
                </table>
            </div>
        </div>

        <!-- Best Practices -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Best Practices & Gotchas</span>
            </div>
            <div class="collapsible-content">

                <div class="card priority" style="margin-bottom: 8px;">
                    <h4>✅ DO: Configuration as Inline Object</h4>
                    <pre><code># CORRECT ✅
config={
    "tools": {"web_search": true},
    "approval_policy": "never"
}

# WRONG ❌ - Causes hanging/nested spawning
config="/Users/wz/.codex/codex-search.toml"
profile="search"  # May have issues too</code></pre>
                </div>

                <div class="card priority" style="margin-bottom: 8px;">
                    <h4>✅ DO: Always Use "never" Approval Policy for MCP</h4>
                    <p>You can't respond to approval prompts when Codex runs as a subagent - it will hang waiting for input.</p>
                </div>

                <div class="card priority" style="margin-bottom: 8px;">
                    <h4>✅ DO: Extract ConversationId from Response</h4>
                    <pre><code>result = mcp__codex__codex(...)

# The MCP tool RETURNS the conversationId in the response object:
conversation_id = result["conversationId"]

# Use it to continue the conversation:
mcp__codex__codex-reply(conversationId=conversation_id, prompt="...")</code></pre>
                    <p style="font-size: 11px; margin-top: 4px; color: var(--level-3);">The conversationId is automatically returned by the tool - you don't need to look it up in files!</p>
                </div>

                <div class="card priority" style="margin-bottom: 8px;">
                    <h4>✅ DO: Enable Web Search for Research Tasks</h4>
                    <p>Always include <code>"tools": {"web_search": true}</code> when you want Codex to research online.</p>
                </div>

                <div class="card" style="margin-bottom: 8px;">
                    <h4>⚠️ GOTCHA: Read-Only is Default for Safety</h4>
                    <p>Unless you specify <code>sandbox_mode</code>, Codex defaults to <code>read-only</code> for version-controlled repos.</p>
                </div>

                <div class="card" style="margin-bottom: 8px;">
                    <h4>⚠️ GOTCHA: Network Blocked in Workspace-Write</h4>
                    <p>Even in <code>workspace-write</code> mode, network is disabled unless you explicitly enable it:</p>
                    <pre><code>config={
    "sandbox_mode": "workspace-write",
    "sandbox_workspace_write": {
        "network_access": true
    }
}</code></pre>
                </div>

                <div class="card priority" style="margin-bottom: 8px;">
                    <h4>💡 ALWAYS: Use High Reasoning Effort</h4>
                    <pre><code>config={
    "model_reasoning_effort": "high",      # ALWAYS use "high" for Codex MCP!
    "model_reasoning_summary": "concise"
}</code></pre>
                    <p style="font-size: 11px; margin-top: 4px; color: var(--level-1); font-weight: 600;">Since Codex MCP is ONLY used for complex analytical tasks, always set reasoning effort to "high".</p>
                </div>

                <div class="card" style="margin-bottom: 8px;">
                    <h4>💡 TIP: Session Files Contain Full History</h4>
                    <p>The <code>rollout-*.jsonl</code> files contain the complete conversation. You can inspect them for debugging:</p>
                    <pre><code>cat ~/.codex/sessions/2025/10/07/rollout-*.jsonl | jq .</code></pre>
                </div>
            </div>
        </div>

        <!-- Recommended Configs -->
        <div class="collapsible open">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Recommended Configurations for Common Tasks</span>
            </div>
            <div class="collapsible-content">
                <div class="two-column-layout">
                    <div class="card priority">
                        <h4>🔍 Research & Analysis (Standard)</h4>
                        <pre><code>{
  "tools": {"web_search": true},
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>

                    <div class="card priority">
                        <h4>📋 Plan Review</h4>
                        <pre><code>{
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>

                    <div class="card priority">
                        <h4>🐛 Bug Investigation</h4>
                        <pre><code>{
  "tools": {"web_search": true},
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise",
  "cwd": "/path/to/project"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>

                    <div class="card priority">
                        <h4>🏗️ Architecture Analysis</h4>
                        <pre><code>{
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise",
  "cwd": "/path/to/project"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>

                    <div class="card priority">
                        <h4>🔬 Deep Code Analysis</h4>
                        <pre><code>{
  "tools": {"web_search": true},
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>

                    <div class="card priority">
                        <h4>📚 Documentation Research</h4>
                        <pre><code>{
  "tools": {"web_search": true},
  "model": "gpt-5-codex",
  "approval_policy": "never",
  "sandbox_mode": "read-only",
  "model_reasoning_effort": "high",
  "model_reasoning_summary": "concise"
}</code></pre>
                        <span class="tag safe">SAFE</span>
                        <span class="tag info">RECOMMENDED</span>
                    </div>
                </div>

                <div class="info-box" style="margin-top: 12px;">
                    <strong>📌 Note:</strong> All recommended configs use <code>read-only</code> mode. Codex MCP is for analysis, not code generation. All configs use <code>gpt-5-codex</code> for best reasoning capabilities.
                </div>
            </div>
        </div>

        <!-- Troubleshooting -->
        <div class="collapsible">
            <div class="collapsible-header">
                <span><span class="arrow">▶</span>Troubleshooting Common Issues</span>
            </div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Problem</th>
                        <th>Cause</th>
                        <th>Solution</th>
                    </tr>
                    <tr>
                        <td>MCP call hangs/times out</td>
                        <td>Using <code>profile</code> or file path in config</td>
                        <td>Use inline config object instead</td>
                    </tr>
                    <tr>
                        <td>Codex waiting for approval</td>
                        <td>Approval policy not set to <code>"never"</code></td>
                        <td>Add <code>"approval_policy": "never"</code> to config</td>
                    </tr>
                    <tr>
                        <td>Can't write files</td>
                        <td>Sandbox mode is <code>read-only</code></td>
                        <td>Change to <code>"sandbox_mode": "workspace-write"</code></td>
                    </tr>
                    <tr>
                        <td>Network requests blocked</td>
                        <td>Network disabled in sandbox</td>
                        <td>Set <code>sandbox_workspace_write.network_access: true</code></td>
                    </tr>
                    <tr>
                        <td>Web search not working</td>
                        <td><code>web_search</code> tool not enabled</td>
                        <td>Add <code>"tools": {"web_search": true}</code></td>
                    </tr>
                    <tr>
                        <td>Can't resume session</td>
                        <td>Wrong conversation ID</td>
                        <td>Check session files in <code>~/.codex/sessions/</code></td>
                    </tr>
                </table>
            </div>
        </div>

        <div class="divider"></div>

        <div class="critical-box">
            <h2>🎓 Quick Reference Cheat Sheet</h2>
            <div class="two-column-layout">
                <div>
                    <h4>Starting a Session</h4>
                    <pre><code>result = mcp__codex__codex(
  prompt="Task description",
  config={
    "tools": {"web_search": true},
    "approval_policy": "never",
    "sandbox_mode": "read-only"
  }
)
conv_id = result["conversationId"]</code></pre>
                </div>
                <div>
                    <h4>Continuing a Session</h4>
                    <pre><code>mcp__codex__codex-reply(
  conversationId=conv_id,
  prompt="Follow-up question"
)</code></pre>
                </div>
            </div>

            <h4 style="margin-top: 12px;">Essential Config Keys (Standard Template)</h4>
            <ul class="dense-list">
                <li><code>"model": "gpt-5-codex"</code> - ALWAYS use gpt-5-codex</li>
                <li><code>"sandbox_mode": "read-only"</code> - ALWAYS use read-only for analysis</li>
                <li><code>"approval_policy": "never"</code> - REQUIRED for MCP (can't respond to prompts)</li>
                <li><code>"model_reasoning_effort": "high"</code> - ALWAYS use "high"</li>
                <li><code>"model_reasoning_summary": "concise"</code> - ALWAYS use "concise" for clear reasoning</li>
                <li><code>"tools": {"web_search": true}</code> - Enable web research (when needed)</li>
                <li><code>"cwd": "/path"</code> - Set working directory (optional)</li>
            </ul>

            <h4 style="margin-top: 12px;">Standard Config Template</h4>
            <pre style="margin-top: 4px;"><code>config={
    "model": "gpt-5-codex",
    "sandbox_mode": "read-only",
    "approval_policy": "never",
    "model_reasoning_effort": "high",
    "model_reasoning_summary": "concise",
    "tools": {"web_search": true}  # Add when needed
}</code></pre>

            <h4 style="margin-top: 12px;">ConversationId Extraction</h4>
            <pre style="margin-top: 4px;"><code>result = mcp__codex__codex(prompt="...", config={...})
conv_id = result["conversationId"]  # Returned by the tool!
mcp__codex__codex-reply(conversationId=conv_id, prompt="...")</code></pre>
        </div>

    </div>

    <script>
        // Toggle individual collapsibles
        document.querySelectorAll('.collapsible-header').forEach(header => {
            header.addEventListener('click', function() {
                this.parentElement.classList.toggle('open');
            });
        });

        // Toggle all collapsibles
        function toggleAll() {
            const collapsibles = document.querySelectorAll('.collapsible');
            const anyOpen = Array.from(collapsibles).some(c => c.classList.contains('open'));

            collapsibles.forEach(c => {
                if (anyOpen) {
                    c.classList.remove('open');
                } else {
                    c.classList.add('open');
                }
            });

            const button = document.querySelector('.toggle-all');
            button.textContent = anyOpen ? 'Expand All Sections' : 'Collapse All Sections';
        }
    </script>
</body>
</html>